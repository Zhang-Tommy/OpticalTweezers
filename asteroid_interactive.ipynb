{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8osnPDRABReJ"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "from IPython.display import display\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "np.seterr(invalid=\"ignore\")\n",
        "\n",
        "import matplotlib.pyplot as plt; plt.rcParams.update({'font.size': 20})\n",
        "import matplotlib.collections\n",
        "import matplotlib.transforms\n",
        "from ipywidgets import interact, interactive\n",
        "\n",
        "from typing import Callable, NamedTuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "QOp7cmtSBRbl"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LinearDynamics(NamedTuple):\n",
        "    f_x: jnp.array  # A\n",
        "    f_u: jnp.array  # B\n",
        "\n",
        "    def __call__(self, x, u, k=None):\n",
        "        f_x, f_u = self\n",
        "        return f_x @ x + f_u @ u if k is None else self[k](x, u)\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        return jax.tree_map(lambda x: x[key], self)\n",
        "\n",
        "\n",
        "class AffinePolicy(NamedTuple):\n",
        "    l: jnp.array  # l\n",
        "    l_x: jnp.array  # L\n",
        "\n",
        "    def __call__(self, x, k=None):\n",
        "        l, l_x = self\n",
        "        return l + l_x @ x if k is None else self[k](x)\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        return jax.tree_map(lambda x: x[key], self)\n",
        "\n",
        "\n",
        "class QuadraticCost(NamedTuple):\n",
        "    c: jnp.array  # c\n",
        "    c_x: jnp.array  # q\n",
        "    c_u: jnp.array  # r\n",
        "    c_xx: jnp.array  # Q\n",
        "    c_uu: jnp.array  # R\n",
        "    c_ux: jnp.array  # H.T\n",
        "\n",
        "    @classmethod\n",
        "    def from_pure_quadratic(cls, c_xx, c_uu, c_ux):\n",
        "        return cls(\n",
        "            jnp.zeros((c_xx.shape[:-2])),\n",
        "            jnp.zeros(c_xx.shape[:-1]),\n",
        "            jnp.zeros(c_uu.shape[:-1]),\n",
        "            c_xx,\n",
        "            c_uu,\n",
        "            c_ux,\n",
        "        )\n",
        "\n",
        "    def __call__(self, x, u, k=None):\n",
        "        c, c_x, c_u, c_xx, c_uu, c_ux = self\n",
        "        return c + c_x @ x + c_u @ u + x @ c_xx @ x / 2 + u @ c_uu @ u / 2 + u @ c_ux @ x if k is None else self[k](x)\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        return jax.tree_map(lambda x: x[key], self)\n",
        "\n",
        "\n",
        "class QuadraticStateCost(NamedTuple):\n",
        "    v: jnp.array  # p (scalar)\n",
        "    v_x: jnp.array  # p (vector)\n",
        "    v_xx: jnp.array  # P\n",
        "\n",
        "    @classmethod\n",
        "    def from_pure_quadratic(cls, v_xx):\n",
        "        return cls(\n",
        "            jnp.zeros(v_xx.shape[:-2]),\n",
        "            jnp.zeros(v_xx.shape[:-1]),\n",
        "            v_xx,\n",
        "        )\n",
        "\n",
        "    def __call__(self, x, k=None):\n",
        "        v, v_x, v_xx = self\n",
        "        return v + v_x @ x + x @ v_xx @ x / 2 if k is None else self[k](x)\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        return jax.tree_map(lambda x: x[key], self)\n",
        "\n",
        "\n",
        "def rollout_state_feedback_policy(dynamics, policy, x0, step_range, x_nom=None, u_nom=None):\n",
        "    def scan_fn(x, k):\n",
        "        u = policy(x, k) if x_nom is None else u_nom[k] + policy(x - x_nom[k], k)\n",
        "        x1 = dynamics(x, u, k)\n",
        "        return (x1, (x1, u))\n",
        "\n",
        "    xs, us = jax.lax.scan(scan_fn, x0, step_range)[1]\n",
        "    return jnp.concatenate([x0[None], xs]), us\n",
        "\n",
        "\n",
        "def riccati_step(\n",
        "    current_step_dynamics: LinearDynamics,\n",
        "    current_step_cost: QuadraticCost,\n",
        "    next_state_value: QuadraticStateCost,\n",
        "):\n",
        "    f_x, f_u = current_step_dynamics\n",
        "    c, c_x, c_u, c_xx, c_uu, c_ux = current_step_cost\n",
        "    v, v_x, v_xx = next_state_value\n",
        "\n",
        "    q = c + v\n",
        "    q_x = c_x + f_x.T @ v_x\n",
        "    q_u = c_u + f_u.T @ v_x\n",
        "    q_xx = c_xx + f_x.T @ v_xx @ f_x\n",
        "    q_uu = c_uu + f_u.T @ v_xx @ f_u\n",
        "    q_ux = c_ux + f_u.T @ v_xx @ f_x\n",
        "\n",
        "    l = -jnp.linalg.solve(q_uu, q_u)\n",
        "    l_x = -jnp.linalg.solve(q_uu, q_ux)\n",
        "\n",
        "    current_state_value = QuadraticStateCost(\n",
        "        q - l.T @ q_uu @ l / 2,\n",
        "        q_x - l_x.T @ q_uu @ l,\n",
        "        q_xx - l_x.T @ q_uu @ l_x,\n",
        "    )\n",
        "    current_step_optimal_policy = AffinePolicy(l, l_x)\n",
        "    return current_state_value, current_step_optimal_policy\n",
        "\n",
        "\n",
        "def ensure_positive_definite(a, eps=1e-3):\n",
        "    w, v = jnp.linalg.eigh(a)\n",
        "    return (v * jnp.maximum(w, eps)) @ v.T\n",
        "\n",
        "\n",
        "class TotalCost(NamedTuple):\n",
        "    running_cost: Callable\n",
        "    terminal_cost: Callable\n",
        "\n",
        "    def __call__(self, xs, us):\n",
        "        step_range = jnp.arange(us.shape[0])\n",
        "        return jnp.sum(jax.vmap(self.running_cost)(xs[:-1], us, step_range)) + self.terminal_cost(xs[-1])\n",
        "\n",
        "\n",
        "class EulerIntegrator(NamedTuple):\n",
        "    \"\"\"Discrete time dynamics from time-invariant continuous time dynamics using the Euler method.\"\"\"\n",
        "    ode: Callable\n",
        "    dt: float\n",
        "\n",
        "    @jax.jit\n",
        "    def __call__(self, x, u, k):\n",
        "        return x + self.dt * self.ode(x, u)\n",
        "\n",
        "\n",
        "class RK4Integrator(NamedTuple):\n",
        "    \"\"\"Discrete time dynamics from time-invariant continuous time dynamics using a 4th order Runge-Kutta method.\"\"\"\n",
        "    ode: Callable\n",
        "    dt: float\n",
        "\n",
        "    @jax.jit\n",
        "    def __call__(self, x, u, k):\n",
        "        k1 = self.dt * self.ode(x, u)\n",
        "        k2 = self.dt * self.ode(x + k1 / 2, u)\n",
        "        k3 = self.dt * self.ode(x + k2 / 2, u)\n",
        "        k4 = self.dt * self.ode(x + k3, u)\n",
        "        return x + (k1 + 2 * k2 + 2 * k3 + k4) / 6\n",
        "\n",
        "    #@jax.jit\n",
        "    #def __call__(self, x, u, k):\n",
        "    #    A = np.array([[4.315e-11, 0],\n",
        "    #                  [0, 4.315e-11]])\n",
        "    #    B = np.array([[1, 0],\n",
        "    #                  [0, 1]])\n",
        "    #    return A@x + B@u\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "# Run every single MPC loop (Every time we plan over the horizon)\n",
        "def iterative_linear_quadratic_regulator(dynamics, total_cost, x0, u_guess, maxiter=100, atol=1e-3):\n",
        "    running_cost, terminal_cost = total_cost\n",
        "    n, (N, m) = x0.shape[-1], u_guess.shape  # Initial state and control inputs\n",
        "    step_range = jnp.arange(N) # 0, 1, 2, 3,..., N - 1\n",
        "\n",
        "    xs, us = rollout_state_feedback_policy(dynamics, lambda x, k: u_guess[k], x0, step_range)\n",
        "    j = total_cost(xs, us)\n",
        "\n",
        "    def continuation_criterion(loop_vars):\n",
        "        i, _, _, j_curr, j_prev = loop_vars\n",
        "        return (j_curr < j_prev - atol) & (i < maxiter)\n",
        "\n",
        "    def ilqr_iteration(loop_vars):\n",
        "        i, xs, us, j_curr, j_prev = loop_vars\n",
        "\n",
        "        f_x, f_u = jax.vmap(jax.jacobian(dynamics, (0, 1)))(xs[:-1], us, step_range)\n",
        "        c = jax.vmap(running_cost)(xs[:-1], us, step_range)\n",
        "        c_x, c_u = jax.vmap(jax.grad(running_cost, (0, 1)))(xs[:-1], us, step_range)\n",
        "        (c_xx, c_xu), (c_ux, c_uu) = jax.vmap(jax.hessian(running_cost, (0, 1)))(xs[:-1], us, step_range)\n",
        "        v, v_x, v_xx = terminal_cost(xs[-1]), jax.grad(terminal_cost)(xs[-1]), jax.hessian(terminal_cost)(xs[-1])\n",
        "\n",
        "        # Ensure quadratic cost terms are positive definite.\n",
        "        c_zz = jnp.block([[c_xx, c_xu], [c_ux, c_uu]])\n",
        "        c_zz = jax.vmap(ensure_positive_definite)(c_zz)\n",
        "        c_xx, c_uu, c_ux = c_zz[:, :n, :n], c_zz[:, -m:, -m:], c_zz[:, -m:, :n]\n",
        "        v_xx = ensure_positive_definite(v_xx)\n",
        "\n",
        "        linearized_dynamics = LinearDynamics(f_x, f_u)\n",
        "        quadratized_running_cost = QuadraticCost(c, c_x, c_u, c_xx, c_uu, c_ux)\n",
        "        quadratized_terminal_cost = QuadraticStateCost(v, v_x, v_xx)\n",
        "\n",
        "        def scan_fn(next_state_value, current_step_dynamics_cost):\n",
        "            current_step_dynamics, current_step_cost = current_step_dynamics_cost\n",
        "            current_state_value, current_step_policy = riccati_step(\n",
        "                current_step_dynamics,\n",
        "                current_step_cost,\n",
        "                next_state_value,\n",
        "            )\n",
        "            return current_state_value, current_step_policy\n",
        "\n",
        "        policy = jax.lax.scan(scan_fn,\n",
        "                              quadratized_terminal_cost, (linearized_dynamics, quadratized_running_cost),\n",
        "                              reverse=True)[1]\n",
        "\n",
        "        def rollout_linesearch_policy(alpha):\n",
        "            # Note that we roll out the true `dynamics`, not the `linearized_dynamics`!\n",
        "            l, l_x = policy\n",
        "            return rollout_state_feedback_policy(dynamics, AffinePolicy(alpha * l, l_x), x0, step_range, xs, us)\n",
        "\n",
        "        # Backtracking line search (step sizes evaluated in parallel).\n",
        "        all_xs, all_us = jax.vmap(rollout_linesearch_policy)(0.5**jnp.arange(16))\n",
        "        js = jax.vmap(total_cost)(all_xs, all_us)\n",
        "        a = jnp.argmin(js)\n",
        "        j = js[a]\n",
        "        xs = jnp.where(j < j_curr, all_xs[a], xs)\n",
        "        us = jnp.where(j < j_curr, all_us[a], us)\n",
        "        return i + 1, xs, us, jnp.minimum(j, j_curr), j_curr\n",
        "\n",
        "    i, xs, us, j, _ = jax.lax.while_loop(continuation_criterion, ilqr_iteration, (0, xs, us, j, jnp.inf))\n",
        "\n",
        "    return {\n",
        "        \"optimal_trajectory\": (xs, us),\n",
        "        \"optimal_cost\": j,\n",
        "        \"num_iterations\": i,\n",
        "    }\n",
        "\n",
        "\n",
        "class ContinuousTimeBeadDynamics(NamedTuple):\n",
        "    def __call__(self, state, control):\n",
        "        \"\"\"\n",
        "        Full Dynamics: mẍ + ẋβ + k(x - u) = η(t) + F(t)\n",
        "        x : postion of bead\n",
        "        u : postion of trap\n",
        "\n",
        "        m = 0 : (negligible bead mass)\n",
        "        β : damping coefficient (~10e-8)\n",
        "        k : spring constant (~10e-5)\n",
        "        η(t) = 0 : thermal forces on bead (negligible)\n",
        "        F(t) = 0 : external forces on bead (negligible)\n",
        "\n",
        "        Simplified dynamics: ẋβ + k(x - u) = 0\n",
        "\n",
        "        Solve for ẋ: ẋ = k(-x + u) / β\n",
        "        \"\"\"\n",
        "\n",
        "        x, y = state  # x and y positions of the bead\n",
        "        u_x, u_y = control  # x and y positions of the trap\n",
        "        b = 1  # 10e-8\n",
        "        k = 1  # 10e-5\n",
        "        return jnp.array([\n",
        "            (-k * x + k * u_x) / b,\n",
        "            (-k * y + k * u_y) / b\n",
        "        ])\n",
        "\n",
        "\n",
        "\"\"\" Environment Setup \"\"\"\n",
        "class Asteroid(NamedTuple):\n",
        "    center: jnp.array\n",
        "    radius: jnp.array\n",
        "    velocity: float\n",
        "\n",
        "    def at_time(self, time):\n",
        "        return self._replace(center=self.center + self.velocity * time)\n",
        "\n",
        "\n",
        "class Environment(NamedTuple):\n",
        "    asteroids: Asteroid\n",
        "    obj_bead_radius: float\n",
        "    bubble_radius: float\n",
        "    bounds: jnp.array\n",
        "\n",
        "    @classmethod\n",
        "    def create(cls, num_asteroids, obj_bead_radius=1.0, bubble_radius=3.0, bounds=(50, 40)):\n",
        "        bounds = np.array(bounds)\n",
        "        return cls(\n",
        "            Asteroid(\n",
        "                np.random.rand(num_asteroids, 2) * bounds,\n",
        "                np.ones(num_asteroids),\n",
        "                0,\n",
        "            ), obj_bead_radius, bubble_radius, bounds)\n",
        "\n",
        "    def at_time(self, time):\n",
        "        return self._replace(asteroids=self.asteroids.at_time(time))\n",
        "\n",
        "    def wrap_vector(self, vector):\n",
        "        return (vector + self.bounds / 2) % self.bounds - self.bounds / 2\n",
        "    \n",
        "\n",
        "    def plot(self, state=None, plan=None, history=None, ax=None):\n",
        "        if state is None:\n",
        "            state = np.full(3, np.nan)\n",
        "        plan = np.full((0, 2), np.nan) if plan is None else plan[:, :2]\n",
        "        history = np.full((0, 2), np.nan) if history is None else history[:, :2]\n",
        "\n",
        "        if ax is None:\n",
        "            fig, ax = plt.subplots(figsize=(10, 8))\n",
        "            ax.set_xlim(0, self.bounds[0])\n",
        "            ax.set_ylim(0, self.bounds[1])\n",
        "            ax.set_aspect(1)\n",
        "            asteroids = ax.add_collection(\n",
        "                matplotlib.collections.PatchCollection(\n",
        "                    [plt.Circle(np.zeros(2), r) for r in self.asteroids.radius] * 4,\n",
        "                    offsets=np.zeros(2),\n",
        "                    transOffset=matplotlib.transforms.AffineDeltaTransform(ax.transData),\n",
        "                    color=\"black\",\n",
        "                ))\n",
        "            obj_bead = ax.add_collection(\n",
        "                matplotlib.collections.PatchCollection(\n",
        "                    [plt.Circle(np.zeros(2), self.obj_bead_radius)] * 4,\n",
        "                    offsets=np.zeros(2),\n",
        "                    transOffset=matplotlib.transforms.AffineDeltaTransform(ax.transData),\n",
        "                    color=\"red\",\n",
        "                    zorder=10,\n",
        "                ))\n",
        "            circle = ax.add_collection(\n",
        "                matplotlib.collections.PatchCollection(\n",
        "                    [plt.Circle(np.zeros(2), self.bubble_radius)] * 4,\n",
        "                    offsets=np.zeros(2),\n",
        "                    transOffset=matplotlib.transforms.AffineDeltaTransform(ax.transData),\n",
        "                    facecolor=(0, 0, 0, 0),\n",
        "                    edgecolor=\"black\",\n",
        "                    linestyle=\"--\",\n",
        "                    zorder=10,\n",
        "                ))\n",
        "            plan_line = ax.plot(plan[:, 0], plan[:, 1], color=\"green\")[0]\n",
        "            history_line = ax.plot(history[:, 0], history[:, 1], color=\"blue\")[0]\n",
        "        else:\n",
        "            fig = ax.figure\n",
        "            asteroids, obj_bead, circle = ax.collections\n",
        "            plan_line, history_line = ax.lines\n",
        "        screen_offsets = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "        asteroids.set_offsets(\n",
        "            (self.wrap_vector(self.asteroids.center) + self.bounds * screen_offsets[:, None, :]).reshape(-1, 2))\n",
        "\n",
        "        obj_bead.set_offsets((self.wrap_vector(state[:2]) + self.bounds * screen_offsets))\n",
        "        circle.set_offsets((self.wrap_vector(state[:2]) + self.bounds * screen_offsets))\n",
        "\n",
        "        def tile_line(line):\n",
        "            if line.shape[0] == 0:\n",
        "                return line\n",
        "            irange, jrange = [\n",
        "                range(int(x[0]), int(x[1] + 1))\n",
        "                for x in zip(np.min(line, 0) // self.bounds,\n",
        "                             np.max(line, 0) // self.bounds)\n",
        "            ]\n",
        "            return np.concatenate([\n",
        "                np.pad(line - np.array([i, j]) * self.bounds, ((0, 1), (0, 0)), constant_values=np.nan)\n",
        "                for i in irange\n",
        "                for j in jrange\n",
        "            ], 0)\n",
        "\n",
        "        plan_line.set_data(*tile_line(plan).T)\n",
        "        history_line.set_data(*tile_line(history).T)\n",
        "        return fig, ax\n",
        "\n",
        "\n",
        "\"\"\" Running and Total Cost \"\"\"\n",
        "class RunningCost(NamedTuple):\n",
        "    env: Environment\n",
        "    dt: jnp.array\n",
        "\n",
        "    def __call__(self, state, control, step):\n",
        "        # NOTE: many parameters (gains, offsets) in this function could be lifted to fields of `RunningCost`, in which\n",
        "        # case you could experiment with changing these parameters without incurring `jax.jit` recompilation.\n",
        "        asteroids = self.env.asteroids.at_time(step * self.dt)\n",
        "\n",
        "        separation_distance = jnp.where(\n",
        "            jnp.isnan(asteroids.radius), np.inf,\n",
        "            jnp.linalg.norm(self.env.wrap_vector(state[:2] - asteroids.center), axis=-1) - asteroids.radius -\n",
        "            self.env.obj_bead_radius)\n",
        "        collision_avoidance_penalty = jnp.sum(\n",
        "            jnp.where(separation_distance > 0.3, 0, 1e4 * (0.3 - separation_distance)**2))\n",
        "\n",
        "        u_x, u_y = control\n",
        "\n",
        "        u_x_penalty = jnp.where(u_x < 0, 1e8, 1e2*u_x)\n",
        "        u_y_penalty = jnp.where(u_y < 0, 1e8, 1e2*u_y)\n",
        "\n",
        "        u_x_max_penalty = jnp.where(u_x > 120, 1e8, 0)\n",
        "        u_y_max_penalty = jnp.where(u_y > 120, 1e8, 0)\n",
        "        x_dist = jnp.abs(state[0] - u_x)\n",
        "        y_dist = jnp.abs(state[1] - u_y)\n",
        "\n",
        "        #jax.debug.print(\"Dist = {dist}\",dist=dist)\n",
        "\n",
        "        control_penalty = jnp.where(x_dist > 8, 1e8, 0) + jnp.where(y_dist > 8, 1e8, 0)\n",
        "\n",
        "        return collision_avoidance_penalty + u_x_penalty + u_y_penalty #+ u_x_max_penalty + u_y_max_penalty# + control_penalty\n",
        "\n",
        "\n",
        "class FullHorizonTerminalCost(NamedTuple):\n",
        "    env: Environment\n",
        "    goal_position: jnp.array\n",
        "\n",
        "    @classmethod\n",
        "    def create_ignoring_extra_args(cls, env, goal_position, *args, **kwargs):\n",
        "        return cls(env, goal_position)\n",
        "\n",
        "    def __call__(self, state):\n",
        "        return 1000 * (jnp.sum(jnp.square(state[:2] - self.goal_position)) + state[3]**2)\n",
        "\n",
        "# Generate an initial guess for the control sequence\n",
        "def gen_intial_traj(start_state, goal_state, N):\n",
        "    xs, ys = start_state\n",
        "    xg, yg = goal_state\n",
        "\n",
        "    x_traj = np.linspace(xs, xg, N)\n",
        "    y_traj = np.linspace(ys, yg, N)\n",
        "\n",
        "    traj = np.array([x_traj.T, y_traj.T])\n",
        "\n",
        "    return traj\n",
        "\n",
        "start_state = np.array([5., 6.])\n",
        "goal_position = np.array([10., 15.])\n",
        "\n",
        "u_guess = gen_intial_traj(start_state, goal_position, 20).T\n",
        "\"\"\" MPC \"\"\"\n",
        "@functools.partial(jax.jit, static_argnames=[\"running_cost_type\", \"terminal_cost_type\", \"limited_sensing\", \"N\"])\n",
        "def policy(state, env, dynamics, running_cost_type, terminal_cost_type, limited_sensing=False, N=20):\n",
        "    #if limited_sensing:\n",
        "    #    env = env.sense(state[:2])\n",
        "    empty_env = Environment.create(0)\n",
        "    solution = iterative_linear_quadratic_regulator(\n",
        "        dynamics,\n",
        "        TotalCost(\n",
        "            running_cost_type(empty_env, dynamics.dt),\n",
        "            terminal_cost_type.create_ignoring_extra_args(\n",
        "                empty_env,\n",
        "                goal_position,\n",
        "                state[:2],\n",
        "                empty_env.bubble_radius,\n",
        "            ),\n",
        "        ),\n",
        "        state,\n",
        "        u_guess,\n",
        "    )\n",
        "    solution = iterative_linear_quadratic_regulator(\n",
        "        dynamics,\n",
        "        TotalCost(\n",
        "            running_cost_type(env, dynamics.dt),\n",
        "            terminal_cost_type.create_ignoring_extra_args(\n",
        "                env,\n",
        "                goal_position,\n",
        "                state[:2],\n",
        "                env.bubble_radius,\n",
        "            ),\n",
        "        ),\n",
        "        state,\n",
        "        solution[\"optimal_trajectory\"][1],\n",
        "    )\n",
        "    states, controls = solution[\"optimal_trajectory\"]\n",
        "    return controls[0], (states, controls)\n",
        "\n",
        "\n",
        "def simulate_mpc(start_state, env, dynamics, running_cost_type, terminal_cost_type, limited_sensing=False, N=20, T=1250):\n",
        "    states = [start_state]\n",
        "    controls = []\n",
        "    plans = []\n",
        "    for t in range(T):\n",
        "        control, (mpc_states, mpc_controls) = policy(states[-1], env.at_time(t * dynamics.dt), dynamics,\n",
        "                                                     running_cost_type, terminal_cost_type, limited_sensing, N)\n",
        "        states.append(mpc_states[1])\n",
        "        controls.append(control)\n",
        "        plans.append(mpc_states)\n",
        "        #print(mpc_states)\n",
        "    states = np.array(states)\n",
        "    controls = np.array(controls)\n",
        "    plans = np.array(plans)\n",
        "\n",
        "    return states, controls\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Jordan\\AppData\\Local\\Temp\\ipykernel_20652\\3419226819.py:22: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n",
            "  return jax.tree_map(lambda x: x[key], self)\n",
            "C:\\Users\\Jordan\\AppData\\Local\\Temp\\ipykernel_20652\\3419226819.py:22: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n",
            "  return jax.tree_map(lambda x: x[key], self)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "155c16f9ffe049f18c79e9dedc880e4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='k', max=50), Output()), _dom_classes=('widget-interact',…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Problem parameters.\n",
        "T = 50\n",
        "dt = 1\n",
        "\n",
        "dynamics = RK4Integrator(ContinuousTimeBeadDynamics(), dt)\n",
        "\n",
        "np.random.seed(2)\n",
        "env = Environment.create(20)\n",
        "\n",
        "\n",
        "states, controls = simulate_mpc(start_state, env, dynamics, RunningCost, FullHorizonTerminalCost)\n",
        "\n",
        "#print(states)\n",
        "#print(controls)\n",
        "\n",
        "# plt.plot(np.arange(0, len(controls)), controls)\n",
        "# plt.plot(np.arange(0, len(states)), states)\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "fig, ax = env.plot()\n",
        "plt.close()\n",
        "\n",
        "\n",
        "@interact(k=(0, T))\n",
        "def plot(k=0):\n",
        "    env.at_time(k * dt).plot(states[k], states[:k + 1], states[k:], ax=ax)\n",
        "    return fig"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
